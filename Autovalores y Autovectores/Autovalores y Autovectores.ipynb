{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidad Central de Venezuela\n",
    "## Facultad de Ingeniería\n",
    "## Escuela de Ingeniería Eléctrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> Autovalores y Autovectores </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"text-align: right\"> Periodo 2020-3 </div>\n",
    "#### <div style=\"text-align: right\"> 19/01/2021  </div>\n",
    "### <div style=\"text-align: right\"> Prof. Gilberto R. Noguera </div>\n",
    "#### <div style=\"text-align: right\"> Alumno: José Páez C.I.: 24 311 351 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En álgebra lineal, los vectores propios, eigenvectores o autovectores de un operador lineal son los vectores no nulos que, cuando son transformados por el operador, dan lugar a un múltiplo escalar de sí mismos, con lo que no cambian su dirección. Este escalar λ recibe el nombre valor propio, autovalor o valor característico\n",
    "\n",
    "La palabra alemana eigen, que se traduce en español como propio, se usó por primera vez en este contexto por David Hilbert en 1904 (aunque Helmholtz la usó previamente con un significado parecido). Eigen se ha traducido también como inherente, característico o el prefijo auto-, donde se aprecia el énfasis en la importancia de los valores propios para definir la naturaleza única de una determinada transformación lineal. Las denominaciones vector y valor característicos también se utilizan habitualmente. El uso del prefijo auto- es un caso propio y singular que se da solamente en español, portugués e italiano. En otras lenguas con más tradición en Matemáticas (alemán, neerlandés, inglés, francés, ruso, etc.) nadie parece haber traducido eigen- (propio, perteneciente a, etc.) por auto- (que nada tiene que ver con la etimología o el significado del prefijo eigen). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marco Teórico\n",
    "\n",
    "A menudo, una transformación queda completamente determinada por sus vectores propios y valores propios.\n",
    "\n",
    "Las transformaciones lineales del espacio —como la rotación, la reflexión, el ensanchamiento, o cualquier combinación de las anteriores; en esta lista podrían incluirse otras transformaciones— pueden interpretarse mediante el efecto que producen en los vectores. \n",
    "\n",
    "* Los vectores propios de las transformaciones lineales son vectores que, o no son afectados por la transformación o solo resultan multiplicados por un escalar; y, por tanto, no varían su dirección.\n",
    "\n",
    "* El valor propio de un vector propio es el factor de escala por el que ha sido multiplicado.\n",
    "\n",
    "\n",
    "Formalmente, se definen los **Auto Vectores y Auto Valores** de la siguiente manera: \n",
    "\n",
    "Sea $\\mathbf{A}:V\\to V$ un operador lineal en un cierto $\\scriptstyle \\mathbb{K}$-espacio vectorial $V$ y $\\mathbf{v}$ un vector no nulo en $V$. Si existe un escalar $c$ tal que\n",
    "\n",
    "$$\\mathbf{A} \\mathbf{v} = c \\mathbf{v},\\qquad \\mathbf{v}\\ne \\mathbf{0},\\; c \\in \\mathbb{K}\n",
    "$$\n",
    "\n",
    "entonces decimos que $\\mathbf{v}$ es un vector propio del operador '''A''', y su valor propio asociado es $c$. Observe que si $\\mathbf{v}$ es un vector propio con el valor propio $c$ entonces cualquier múltiplo diferente de cero de $\\mathbf{v}$ es también un vector propio con el valor propio $c$. De hecho, todos los vectores propios con el valor propio asociado $c$ junto con '''0''', forman un subespacio de ''V'', el «espacio propio» para el valor propio $c$.\n",
    "\n",
    "\n",
    "**Ejemplos** de esto, serían: \n",
    "\n",
    "A medida que la Tierra rota, los vectores en el eje de rotación permanecen invariantes. Si se considera la transformación lineal que sufre la Tierra tras una hora de rotación, una flecha que partiera del centro de la Tierra al polo Sur geográfico sería un vector propio de esta transformación, pero una flecha que partiera del centro a un punto del ecuador no sería un vector propio. Dado que la flecha que apunta al polo no cambia de longitud por la rotación, su valor propio es 1.\n",
    "\n",
    "Otro ejemplo sería una lámina de metal que se expandiera uniformemente a partir de un punto de tal manera que las distancias desde cualquier punto al punto fijo se duplicasen. Esta expansión es una transformación con valor propio 2. Cada vector desde el punto fijo a cualquier otro es un vector propio, y el espacio propio es el conjunto de todos esos vectores. \n",
    "\n",
    "\n",
    "El **Teorema de Gerschgorin** es utilizado en álgebra lineal para encontrar una cota de los autovalores de una matriz compleja (esto incluye también a las reales) de orden $n\\times n$. Fue publicado por el matemático soviético S.Gerschgorin en 1931.\n",
    "\n",
    "Dada una matriz $A= (a_{ij})\\in M_n(\\mathbb C)$ se definen los círculos  $D_i={z\\in C/ |z-a_{ii}|\\leq r_i}  , i=1...n$ , con centro en $a_{ii}$ y  radio $r_i = \\sum_{j \\neq i}|a_{ij}|$,$j= 1...n$. \n",
    "\n",
    "Teorema: Los valores propios de la matriz $A$ se encuentran en los discos de Gerschgorin. Cada componente conexa formada por $s$ discos tendrá $s$ valores propios reales o complejos.\n",
    "\n",
    "Demostración:  Sea $\\lambda$ un valor propio de $A$ y $x$ un vector propio asociado a $\\lambda$. Supongamos que la componente de mayor valor absoluto de $x$ es la $\\jmath$, es decir, $|x_j|= Max{|x_k|}$, $k= 1...n$. Entonces al multiplicar la fija j de la matriz $A$ por el vector propio $x$, se tiene: \n",
    "\n",
    "$a_{j1} x_1 + ... + a_{jn} x_n = \\lambda x_j \\Longrightarrow \n",
    "|(a_{jj}-\\lambda)x_j|=|\\sum_{k=1, k\\neq j}^n a_{jk} x_j| \\Longrightarrow\n",
    "|a_{jj} - \\lambda||x_j|\\leq \\sum_{k=1,k\\neq j}^n |a_{jk}||x_k|\\leq \\sum_{k=1, k\\neq j}^n |a_{jk}||x_j|= \n",
    "|x_j| \\sum_{k=1, k\\neq j}^n |a_{jk}|\\Longrightarrow |a_{jj}-\\lambda|\\leq \\sum_{k=1, k\\neq j}^n |a_{jk}|= r_j$\n",
    "por tanto $\\lambda$ se encuentra en el disco de Gerschgorin $D_j$. \n",
    "\n",
    "\n",
    "El **Método de la Potencia** es una técnica iterativa que permite determinar el valor caracte­rístico dominante de una matriz, es decir, el valor característico con mayor magnitud. Una ligera modificación del método permite determinar también otros valores característicos. Un aspecto útil del método de la potencia es que no sólo produce un valor característico, sino un vector característico asociado. De hecho, es frecuente que el método de la potencia se aplique para hallar un vector característico de un valor característico determinado por otros medios.\n",
    "\n",
    "Ejemplo:\n",
    "La matriz <img src=\"Matriz A.png\"> tiene los valores característicos A1 = 6, A2 = 3 y A3 = 2. En consecuencia, el método de la potencia  convergirá. Sea x<O) = (1, 1, l)^t, entonces y(1) = Ax(0) = (10, 8, l)t, \n",
    "\n",
    "por lo que \n",
    "\n",
    "||y(1)|| = 10,  μ(1) = Y1 (1) = 10 y (l) x(1) = y(1)/10 = (1 , 0.8, O l)^t \n",
    "\n",
    "Continuando en esta forma se generan los valores de la tabla 9.1 presentada adelante, donde μ^(m) representa la secuencia generada por el procedimiento de Aitken  Δ^2. En esta etapa, una aproximación al valor característico dominante, 6, es μ^(10) = 6.000000 con el vector característico unitario aproximado (1, 0.714316, -0.249895)^t. Aunque la aproximación al valor característico es correcta hasta las cifras enumeradas, la aproximación al vector característico es mucho menos cercana al verdadero vector característico (1, 0.714286, -0.25)^t. \n",
    "\n",
    "<img src=\"Tabla 9.1.png\">\n",
    "\n",
    "\n",
    "Cuando A es **Simétrica**, podemos hacer una variación en la elección de los vectores x(m), y(m) y escalares μ(m) para mejorar significativamente la razón de convergencia entre la sucesión {μ(m) }m=l ^∞  y el valor característico dominante A1. De hecho, aunque la razón de convergencia del método general de potencia es O(|A2/ A1|^m), la del método modificado q para matrices simétricas es O(|A2/A1|^2m) (Más rapido).\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La Matriz <img src=\"Matriz A2.png\">\n",
    "\n",
    "es simétrica con los valores característicos A1 = 6, A2 = 3 y A3 = l. La tabla 9.2 enumera los resultados del método de la potencia, y los resultados de la tabla 9.3 provienen del método de la potencia simétrica, suponiendo en cada caso que y(O) = x(0) = (1, O, O)^t. Observe la mejora significativa proporcionada por el método de la potencia simétrica. Las aproximaciones a los vectores característicos producidos con el método de la potencia convergen en (1, -1, t)^t, un vector con ||(1, -1, 1)^t||∞ = l. En el método de la potencia simétrica, la convergencia es hacia el vector paralelo (√3/3, -√3/3, √3/3)^t, con ||(√3/3, -√3/3, √3/3)^t||2 = 1.\n",
    "\n",
    "<img src=\"Tabla 9.2.png\">\n",
    "<img src=\"Tabla 9.3.png\">\n",
    "\n",
    "\n",
    "El **Método de la potencia inversa** es una modificación del método de la potencia que ofrece una convergencia más rápida. Se basa en las siguientes propiedades:\n",
    " \n",
    "* Dada una matriz A con uno de sus autovalores λ y x su correspondiente autovector. Para una constante α se cumple(A−αI)x= (λ−α)x\n",
    "\n",
    "* Dada una matriz A con uno de sus autovalores λ y x su correspondiente autovector. Si λ distinto de α se tiene que 1/λ−α es autovalor de (A−αI)^−1 y su correspondiente autovector es x.\n",
    "\n",
    "* Si se conoce una aproximación α de uno de los autovalores de A. Se aplica el método de la potencia a la matriz (A−αI)^−1 para obtener el autovalor dominante μ y su correspondiente autovector x.\n",
    "\n",
    "* El autovalor λ de la matriz A es λ = 1/μ+α \n",
    "\n",
    "* Hay que tener en cuenta que al implementar el metodo de la potencia inversa hay que calcular productos(A−αI)^−1 *v = y\n",
    "\n",
    "Estos productos se calculan resolviendo los sistemas(A−αI)y=v\n",
    "\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La matriz\n",
    "\n",
    "\n",
    "se consideró en el ejemplo del método de la potencia, dando la aproximación µ,02) = 6.000837 por medio de x<0> = (1, 1, l)l. Con x<0> = (1, 1, 1)1,  tenemos\n",
    "\n",
    " q = x(0)^t *Ax(O) / x(O)t  *x(O) = 19/3 = 6.333333. \n",
    " \n",
    " En la tabla 9.4 se incluyen los resultados obtenidos al aplicar el método de la potencia inversa y el método  Δ^2 de Aitken a µ(m).\n",
    " \n",
    " <img src=\"Tabla 9.4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 -3  6]\n",
      " [ 0  3 -4]\n",
      " [ 0  2 -3]]\n",
      "[0.26829551 0.69235452 0.612324  ]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[2, -3, 6],\n",
    "              [0, 3, -4],\n",
    "              [0, 2, -3]])\n",
    "\n",
    "\n",
    "x = np.random.rand(a.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método de la Potencia\n",
    "import numpy as np\n",
    "def Potencia(x,a):  \n",
    "    def normalizar(x):\n",
    "        fac= abs(x).max()\n",
    "        x_n= x / x.max()\n",
    "        return fac, x_n\n",
    "\n",
    "\n",
    "    for i in range(8):\n",
    "        x = np.dot(a, x) \n",
    "        lambda_1, x= normalizar(x)\n",
    "    return lambda_1, x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Método de la Potencia inversa\n",
    "import numpy as np\n",
    "import math\n",
    "from random import random\n",
    "\n",
    "from numpy import dot\n",
    "\n",
    "def LUdecomp(a):\n",
    "    n = len(a)\n",
    "    for k in range(0,n-1):\n",
    "        for i in range(k+1,n):\n",
    "           if abs(a[i,k]) > 1.0e-9:\n",
    "               lam = a [i,k]/a[k,k]\n",
    "               a[i,k+1:n] = a[i,k+1:n] - lam*a[k,k+1:n]\n",
    "               a[i,k] = lam\n",
    "    return a\n",
    "\n",
    "def LUsol(a,b):\n",
    "    n = len(a)\n",
    "    for k in range(1,n):\n",
    "        b[k] = b[k] - dot(a[k,0:k],b[0:k])\n",
    "    b[n-1] = b[n-1]/a[n-1,n-1]    \n",
    "    for k in range(n-2,-1,-1):\n",
    "       b[k] = (b[k] - dot(a[k,k+1:n],b[k+1:n]))/a[k,k]\n",
    "    return b\n",
    "\n",
    "def Potenciainv(a,s,tol=1.0e-6):\n",
    "    n = len(a)\n",
    "    aEstrella = a - np.identity(n)*s  # Formar [a*] = [a] - s[I]\n",
    "    aEstrella = LUdecomp(aEstrella)       # Descomponer [a*]\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n):            # Llenar [x] con números random\n",
    "        x[i] = random()\n",
    "    xMag = math.sqrt(np.dot(x,x)) # Normalizar [x]\n",
    "    x =x/xMag\n",
    "    for i in range(50):           # Comenzar iteraciones\n",
    "        xViejo = x.copy()           # Salvar actual [x]\n",
    "        x = LUsol(aEstrella,x)      # Resolver [a*][x] = [xViejo]\n",
    "        xMag = math.sqrt(np.dot(x,x)) # Normalizar [x]\n",
    "        x = x/xMag\n",
    "        if np.dot(xViejo,x) < 0.0:  # Detectar cambio de signo en [x]\n",
    "            sign = -1.0\n",
    "            x=-x\n",
    "        else: sign = 1.0\n",
    "        if math.sqrt(np.dot(xViejo - x,xViejo - x)) < tol:\n",
    "            return s + sign/xMag,x\n",
    "    print(\"El método de la potencia inversa no converge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.16666667])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Polinomio caracteristico\n",
    "\n",
    "import numpy as np\n",
    "def PolCaract(P):\n",
    "    return np.poly(P) # Regresa los coeficientes del polinomio, de mayor a menor grado.\n",
    "\n",
    "#Prueba Polinomio Caracteristico\n",
    "\n",
    "P = np.array([[0, 1./3], [-1./2, 0]])\n",
    "\n",
    "PolCaract(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalor = 3.999949137887188\n",
      "\n",
      "Eigenvector:\n",
      " [0.50000636 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Prueba Método de la Potencia\n",
    "x = np.array([1, 1])\n",
    "a = np.array([[0, 2],\n",
    "              [2, 3]])\n",
    "\n",
    "lam,x = Potencia(x,a)\n",
    "print(\"Eigenvalor =\",lam)\n",
    "print(\"\\nEigenvector:\\n\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalor = 4.87394637864921\n",
      "\n",
      "Eigenvector:\n",
      " [-0.26726603  0.74142854  0.05017271 -0.59491453  0.14970633]\n"
     ]
    }
   ],
   "source": [
    "#Prueba Método de la Potencia Inversa\n",
    "s = 5.0\n",
    "a = np.array([[ 11.0, 2.0,  3.0,  1.0,  4.0],  \n",
    "              [  2.0, 9.0,  3.0,  5.0,  2.0],  \n",
    "              [  3.0, 3.0, 15.0,  4.0,  3.0],  \n",
    "              [  1.0, 5.0,  4.0, 12.0,  4.0],  \n",
    "              [  4.0, 2.0,  3.0,  4.0, 17.0]])\n",
    "lam,x = Potenciainv(a,s)\n",
    "print(\"Eigenvalor =\",lam)\n",
    "print(\"\\nEigenvector:\\n\",x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "La importancia de los Autovalores y Autovectores se ve reflejada en las diversas aplicaciones en distintas ramas de la ciencia tales como:\n",
    "\n",
    "* Ecuación de Schrödinger:\n",
    "\n",
    "Un ejemplo de una ecuación de valor propio donde la transformación T se representa en términos de un operador diferencial es la ecuación de Schrödinger independiente del tiempo de la mecánica cuántica: \n",
    "  $$H\\Psi_E = E\\Psi_E\\,$$\n",
    "\n",
    "Donde H, el Hamiltoniano, es un operador diferencial de segundo orden y Ψ E  la función de onda, es una de las funciones propias correspondientes al valor propio E, interpretado como la energía.\n",
    "\n",
    "* Orbitales moleculares:\n",
    "\n",
    "En mecánica cuántica, y en particular en física atómica y molecular, y en el contexto de la teoría de Hartree-Fock, los orbitales atómicos y moleculares pueden definirse por los vectores propios del operador de Fock. Los valores propios correspondientes son interpretados como potenciales de ionización a través del teorema de Koopmans. \n",
    "\n",
    "* Análisis factorial:\n",
    "\n",
    "En análisis factorial, los valores propios de la matriz de covarianza corresponden a los factores, y los valores propios a las cargas.\n",
    "\n",
    "* Caras propias:\n",
    "\n",
    "En procesado de imagen, las imágenes procesadas de caras pueden verse como vectores cuyas componentes son la luminancia de cada píxel. La dimensión de este espacio vectorial es el número de píxeles. Los vectores propios de la matriz de covarianza asociada a un conjunto amplio de imágenes normalizadas de rostros se llaman caras propias.\n",
    "\n",
    "* Tensor de inercia:\n",
    "\n",
    "En mecánica, los vectores propios del momento de inercia definen los ejes principales de un cuerpo rígido. El tensor de inercia es necesario para determinar la rotación de un cuerpo rígido alrededor de su centro de masa. Los valores propios definen los momentos máximos y mínimos obtenidos mediante el círculo de Mohr. \n",
    "\n",
    "* Tensor de tensión:\n",
    "\n",
    "En mecánica de sólidos deformables, el tensor de tensión es simétrico, así que puede descomponerse en un tensor diagonal cuyos valores propios en la diagonal y los vectores propios forman una base. \n",
    "\n",
    "* Valores propios de un grafo\n",
    "\n",
    "En teoría espectral de grafos, un valor propio de un grafo se define como un valor propio de la matriz de adyacencia del grafo A, o de la matriz Laplaciana del grafo I − T^(− 1 / 2) A T^(− 1 / 2) , donde T es una matriz diagonal que contiene el grado de cada vértice, y en T^( − 1 / 2) , 0 se substituye por 0^(− 1 / 2) . El vector propio principal de un grafo se usa para medir la centralidad de sus vértices. Un ejemplo es el algoritmo PageRank de Google. El vector propio principal de una matriz de adyacencia modificada del grafo de la web da el page rank en sus componentes. \n",
    "\n",
    "\n",
    "Es por ello, la resolución de problemas como los arriba presentados,  que las técnica aquí expuestas para calcular numéricamente Eigenvectores y Eigenvalores resultan  de especial importancia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "Análisis numérico,10a. ed. Autores : Richard L. Burden ,J. Douglas Faires y Annette M. Burden.\n",
    "\n",
    "Numerical methods in engineering. Autor: Jaan Kiusalaas\n",
    "\n",
    "\n",
    "[Vector propio y valor propio. Wikipedia](https://es.wikipedia.org/wiki/Vector_propio_y_valor_propio)\n",
    "\n",
    "\n",
    "[Teorema de Gerschgorin. Wikipedia](https://es.wikipedia.org/wiki/Teorema_de_Gerschgorin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
